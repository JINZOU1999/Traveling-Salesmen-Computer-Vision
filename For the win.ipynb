{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b7c534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:37:45.451324Z",
     "iopub.status.busy": "2022-04-18T20:37:45.447696Z",
     "iopub.status.idle": "2022-04-18T20:37:51.463235Z",
     "shell.execute_reply": "2022-04-18T20:37:51.462555Z",
     "shell.execute_reply.started": "2022-04-18T19:27:27.621094Z"
    },
    "papermill": {
     "duration": 6.047141,
     "end_time": "2022-04-18T20:37:51.463394",
     "exception": false,
     "start_time": "2022-04-18T20:37:45.416253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import cv2\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "PATH = \"/kaggle/input/tsp-cv\"\n",
    "PATH_TRAIN = os.path.join(PATH, \"train.csv\")\n",
    "PATH_TEST = os.path.join(PATH , 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ec33eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:37:51.512840Z",
     "iopub.status.busy": "2022-04-18T20:37:51.512281Z",
     "iopub.status.idle": "2022-04-18T20:37:51.548918Z",
     "shell.execute_reply": "2022-04-18T20:37:51.548412Z",
     "shell.execute_reply.started": "2022-04-18T19:27:33.925749Z"
    },
    "papermill": {
     "duration": 0.06186,
     "end_time": "2022-04-18T20:37:51.549049",
     "exception": false,
     "start_time": "2022-04-18T20:37:51.487189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(PATH_TRAIN)\n",
    "df_test = pd.read_csv(PATH_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebc836a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:37:51.605781Z",
     "iopub.status.busy": "2022-04-18T20:37:51.605015Z",
     "iopub.status.idle": "2022-04-18T20:37:51.607005Z",
     "shell.execute_reply": "2022-04-18T20:37:51.607364Z",
     "shell.execute_reply.started": "2022-04-18T19:27:33.962970Z"
    },
    "papermill": {
     "duration": 0.037205,
     "end_time": "2022-04-18T20:37:51.607496",
     "exception": false,
     "start_time": "2022-04-18T20:37:51.570291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['image_path'] = PATH + '/'+ df_train['filename'] \n",
    "df_test['image_path'] = PATH + '/'+ df_test['filename'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c531972b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:37:51.655718Z",
     "iopub.status.busy": "2022-04-18T20:37:51.654874Z",
     "iopub.status.idle": "2022-04-18T20:41:58.082080Z",
     "shell.execute_reply": "2022-04-18T20:41:58.081519Z",
     "shell.execute_reply.started": "2022-04-18T19:27:33.981437Z"
    },
    "papermill": {
     "duration": 246.452764,
     "end_time": "2022-04-18T20:41:58.082228",
     "exception": false,
     "start_time": "2022-04-18T20:37:51.629464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "train_height_list = []\n",
    "train_length_list = []\n",
    "for i in range(len(df_train)):\n",
    "    image = mpimg.imread(df_train[\"image_path\"][i])\n",
    "    train_height_list.append(image.shape[0])\n",
    "    train_length_list.append(image.shape[1])\n",
    "\n",
    "df_train['height'] = train_height_list\n",
    "df_train['length'] = train_length_list\n",
    "\n",
    "test_height_list = []\n",
    "test_length_list = []\n",
    "for i in range(len(df_test)):\n",
    "    image = mpimg.imread(df_test[\"image_path\"][i])\n",
    "    test_height_list.append(image.shape[0])\n",
    "    test_length_list.append(image.shape[1])\n",
    "\n",
    "df_test['height'] = test_height_list\n",
    "df_test['length'] = test_length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d4f094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:41:58.133034Z",
     "iopub.status.busy": "2022-04-18T20:41:58.132179Z",
     "iopub.status.idle": "2022-04-18T20:42:03.235201Z",
     "shell.execute_reply": "2022-04-18T20:42:03.235763Z",
     "shell.execute_reply.started": "2022-04-18T19:31:33.565675Z"
    },
    "papermill": {
     "duration": 5.131704,
     "end_time": "2022-04-18T20:42:03.235952",
     "exception": false,
     "start_time": "2022-04-18T20:41:58.104248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>distance</th>\n",
       "      <th>image_path</th>\n",
       "      <th>height</th>\n",
       "      <th>length</th>\n",
       "      <th>size_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.jpg</td>\n",
       "      <td>83110</td>\n",
       "      <td>/kaggle/input/tsp-cv/0.jpg</td>\n",
       "      <td>673</td>\n",
       "      <td>503</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1035</td>\n",
       "      <td>/kaggle/input/tsp-cv/1.jpg</td>\n",
       "      <td>222</td>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>20756</td>\n",
       "      <td>/kaggle/input/tsp-cv/2.jpg</td>\n",
       "      <td>999</td>\n",
       "      <td>810</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>13286</td>\n",
       "      <td>/kaggle/input/tsp-cv/3.jpg</td>\n",
       "      <td>717</td>\n",
       "      <td>781</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>13924</td>\n",
       "      <td>/kaggle/input/tsp-cv/4.jpg</td>\n",
       "      <td>884</td>\n",
       "      <td>609</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16013</th>\n",
       "      <td>16014</td>\n",
       "      <td>16014.jpg</td>\n",
       "      <td>1803</td>\n",
       "      <td>/kaggle/input/tsp-cv/16014.jpg</td>\n",
       "      <td>748</td>\n",
       "      <td>839</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16014</th>\n",
       "      <td>16015</td>\n",
       "      <td>16015.jpg</td>\n",
       "      <td>12492</td>\n",
       "      <td>/kaggle/input/tsp-cv/16015.jpg</td>\n",
       "      <td>643</td>\n",
       "      <td>837</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16015</th>\n",
       "      <td>16016</td>\n",
       "      <td>16016.jpg</td>\n",
       "      <td>1556</td>\n",
       "      <td>/kaggle/input/tsp-cv/16016.jpg</td>\n",
       "      <td>938</td>\n",
       "      <td>550</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16016</th>\n",
       "      <td>16017</td>\n",
       "      <td>16017.jpg</td>\n",
       "      <td>16507</td>\n",
       "      <td>/kaggle/input/tsp-cv/16017.jpg</td>\n",
       "      <td>744</td>\n",
       "      <td>845</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16017</th>\n",
       "      <td>16018</td>\n",
       "      <td>16018.jpg</td>\n",
       "      <td>2363</td>\n",
       "      <td>/kaggle/input/tsp-cv/16018.jpg</td>\n",
       "      <td>249</td>\n",
       "      <td>667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16018 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   filename  distance                      image_path  height  \\\n",
       "0          0      0.jpg     83110      /kaggle/input/tsp-cv/0.jpg     673   \n",
       "1          1      1.jpg      1035      /kaggle/input/tsp-cv/1.jpg     222   \n",
       "2          2      2.jpg     20756      /kaggle/input/tsp-cv/2.jpg     999   \n",
       "3          3      3.jpg     13286      /kaggle/input/tsp-cv/3.jpg     717   \n",
       "4          4      4.jpg     13924      /kaggle/input/tsp-cv/4.jpg     884   \n",
       "...      ...        ...       ...                             ...     ...   \n",
       "16013  16014  16014.jpg      1803  /kaggle/input/tsp-cv/16014.jpg     748   \n",
       "16014  16015  16015.jpg     12492  /kaggle/input/tsp-cv/16015.jpg     643   \n",
       "16015  16016  16016.jpg      1556  /kaggle/input/tsp-cv/16016.jpg     938   \n",
       "16016  16017  16017.jpg     16507  /kaggle/input/tsp-cv/16017.jpg     744   \n",
       "16017  16018  16018.jpg      2363  /kaggle/input/tsp-cv/16018.jpg     249   \n",
       "\n",
       "       length  size_cat  \n",
       "0         503         2  \n",
       "1         906         1  \n",
       "2         810         3  \n",
       "3         781         3  \n",
       "4         609         2  \n",
       "...       ...       ...  \n",
       "16013     839         3  \n",
       "16014     837         3  \n",
       "16015     550         2  \n",
       "16016     845         3  \n",
       "16017     667         0  \n",
       "\n",
       "[16018 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height_avg = df_train.height.mean()\n",
    "length_avg = df_train.length.mean()\n",
    "\n",
    "df_train['size_cat'] = [0]*len(df_train)\n",
    "for i in range(len(df_train)):\n",
    "    if df_train['height'][i] <= height_avg:\n",
    "        if df_train['length'][i] <= length_avg:\n",
    "            df_train.loc[i, 'size_cat'] = 0\n",
    "        else:\n",
    "            df_train.loc[i, 'size_cat'] = 1\n",
    "    else:\n",
    "        if df_train['length'][i] <= length_avg:\n",
    "            df_train.loc[i, 'size_cat'] = 2\n",
    "        else:\n",
    "            df_train.loc[i, 'size_cat'] = 3\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07e726fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:42:03.297858Z",
     "iopub.status.busy": "2022-04-18T20:42:03.292410Z",
     "iopub.status.idle": "2022-04-18T20:42:04.355173Z",
     "shell.execute_reply": "2022-04-18T20:42:04.354708Z",
     "shell.execute_reply.started": "2022-04-18T19:31:38.368277Z"
    },
    "papermill": {
     "duration": 1.096457,
     "end_time": "2022-04-18T20:42:04.355304",
     "exception": false,
     "start_time": "2022-04-18T20:42:03.258847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>image_path</th>\n",
       "      <th>height</th>\n",
       "      <th>length</th>\n",
       "      <th>size_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16019</td>\n",
       "      <td>16019.jpg</td>\n",
       "      <td>/kaggle/input/tsp-cv/16019.jpg</td>\n",
       "      <td>395</td>\n",
       "      <td>710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16020</td>\n",
       "      <td>16020.jpg</td>\n",
       "      <td>/kaggle/input/tsp-cv/16020.jpg</td>\n",
       "      <td>651</td>\n",
       "      <td>425</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16021</td>\n",
       "      <td>16021.jpg</td>\n",
       "      <td>/kaggle/input/tsp-cv/16021.jpg</td>\n",
       "      <td>628</td>\n",
       "      <td>559</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16022</td>\n",
       "      <td>16022.jpg</td>\n",
       "      <td>/kaggle/input/tsp-cv/16022.jpg</td>\n",
       "      <td>367</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16023</td>\n",
       "      <td>16023.jpg</td>\n",
       "      <td>/kaggle/input/tsp-cv/16023.jpg</td>\n",
       "      <td>512</td>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>20019</td>\n",
       "      <td>20019.jpg</td>\n",
       "      <td>/kaggle/input/tsp-cv/20019.jpg</td>\n",
       "      <td>499</td>\n",
       "      <td>376</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>20020</td>\n",
       "      <td>20020.jpg</td>\n",
       "      <td>/kaggle/input/tsp-cv/20020.jpg</td>\n",
       "      <td>543</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>20021</td>\n",
       "      <td>20021.jpg</td>\n",
       "      <td>/kaggle/input/tsp-cv/20021.jpg</td>\n",
       "      <td>497</td>\n",
       "      <td>678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>20022</td>\n",
       "      <td>20022.jpg</td>\n",
       "      <td>/kaggle/input/tsp-cv/20022.jpg</td>\n",
       "      <td>605</td>\n",
       "      <td>739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>20023</td>\n",
       "      <td>20023.jpg</td>\n",
       "      <td>/kaggle/input/tsp-cv/20023.jpg</td>\n",
       "      <td>607</td>\n",
       "      <td>515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4005 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   filename                      image_path  height  length  \\\n",
       "0     16019  16019.jpg  /kaggle/input/tsp-cv/16019.jpg     395     710   \n",
       "1     16020  16020.jpg  /kaggle/input/tsp-cv/16020.jpg     651     425   \n",
       "2     16021  16021.jpg  /kaggle/input/tsp-cv/16021.jpg     628     559   \n",
       "3     16022  16022.jpg  /kaggle/input/tsp-cv/16022.jpg     367    1005   \n",
       "4     16023  16023.jpg  /kaggle/input/tsp-cv/16023.jpg     512     464   \n",
       "...     ...        ...                             ...     ...     ...   \n",
       "4000  20019  20019.jpg  /kaggle/input/tsp-cv/20019.jpg     499     376   \n",
       "4001  20020  20020.jpg  /kaggle/input/tsp-cv/20020.jpg     543     403   \n",
       "4002  20021  20021.jpg  /kaggle/input/tsp-cv/20021.jpg     497     678   \n",
       "4003  20022  20022.jpg  /kaggle/input/tsp-cv/20022.jpg     605     739   \n",
       "4004  20023  20023.jpg  /kaggle/input/tsp-cv/20023.jpg     607     515   \n",
       "\n",
       "      size_cat  \n",
       "0            1  \n",
       "1            2  \n",
       "2            2  \n",
       "3            1  \n",
       "4            0  \n",
       "...        ...  \n",
       "4000         0  \n",
       "4001         0  \n",
       "4002         1  \n",
       "4003         1  \n",
       "4004         0  \n",
       "\n",
       "[4005 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['size_cat'] = [0]*len(df_test)\n",
    "for i in range(len(df_test)):\n",
    "    if df_test['height'][i] <= height_avg:\n",
    "        if df_test['length'][i] <= length_avg:\n",
    "            df_test.loc[i, 'size_cat'] = 0\n",
    "        else:\n",
    "            df_test.loc[i, 'size_cat'] = 1\n",
    "    else:\n",
    "        if df_test['length'][i] <= length_avg:\n",
    "            df_test.loc[i, 'size_cat'] = 2\n",
    "        else:\n",
    "            df_test.loc[i, 'size_cat'] = 3\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab17bbb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:42:04.409279Z",
     "iopub.status.busy": "2022-04-18T20:42:04.408404Z",
     "iopub.status.idle": "2022-04-18T20:42:04.413628Z",
     "shell.execute_reply": "2022-04-18T20:42:04.413147Z",
     "shell.execute_reply.started": "2022-04-18T19:31:39.597753Z"
    },
    "papermill": {
     "duration": 0.034607,
     "end_time": "2022-04-18T20:42:04.413751",
     "exception": false,
     "start_time": "2022-04-18T20:42:04.379144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc719013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:42:04.463922Z",
     "iopub.status.busy": "2022-04-18T20:42:04.463074Z",
     "iopub.status.idle": "2022-04-18T20:42:04.476936Z",
     "shell.execute_reply": "2022-04-18T20:42:04.476454Z",
     "shell.execute_reply.started": "2022-04-18T19:31:39.608222Z"
    },
    "papermill": {
     "duration": 0.039419,
     "end_time": "2022-04-18T20:42:04.477049",
     "exception": false,
     "start_time": "2022-04-18T20:42:04.437630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(df_train,df_test):    \n",
    "    TRAIN_PCT = 0.8\n",
    "    TRAIN_CUT = int(len(df_train) * TRAIN_PCT)\n",
    "\n",
    "    df_train_cut = df_train[0:TRAIN_CUT]\n",
    "    df_validate_cut = df_train[TRAIN_CUT:]\n",
    "    WIDTH = 299\n",
    "    HEIGHT = 299\n",
    "\n",
    "    training_datagen = ImageDataGenerator(\n",
    "      rescale = 1./255,\n",
    "      horizontal_flip=True,\n",
    "      #vertical_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "    train_generator = training_datagen.flow_from_dataframe(\n",
    "            dataframe=df_train_cut,\n",
    "            directory=PATH,\n",
    "            x_col=\"filename\",\n",
    "            y_col=\"distance\",\n",
    "            target_size=(HEIGHT, WIDTH),\n",
    "            batch_size=32, # Keeping the training batch size small USUALLY increases performance\n",
    "            class_mode='raw')\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    val_generator = validation_datagen.flow_from_dataframe(\n",
    "            dataframe=df_validate_cut,\n",
    "            directory=PATH,\n",
    "            x_col=\"filename\",\n",
    "            y_col=\"distance\",\n",
    "            target_size=(HEIGHT, WIDTH),\n",
    "            batch_size=256, # Make the validation batch size as large as you have memory for\n",
    "            class_mode='raw')\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "            dataframe=df_test,\n",
    "            directory=PATH,\n",
    "            x_col=\"filename\",\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            target_size=(HEIGHT, WIDTH),\n",
    "            class_mode=None)\n",
    "\n",
    "    input_tensor = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "\n",
    "    base_model = Xception(\n",
    "        include_top=False, weights='imagenet', input_tensor=input_tensor,\n",
    "        input_shape=None)\n",
    "\n",
    "    x=base_model.output\n",
    "    x=GlobalAveragePooling2D()(x)\n",
    "    x=Dense(2048,activation='relu')(x) \n",
    "    x=Dense(2048,activation='relu')(x) \n",
    "    model=Model(inputs=base_model.input,outputs=Dense(1)(x))\n",
    "\n",
    "    # Important, calculate a valid step size for the validation dataset\n",
    "    STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "    STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
    "    base_model.trainable = True\n",
    "    model.compile(loss = 'mean_squared_error', optimizer='adam', metrics=[RootMeanSquaredError(name=\"rmse\")])\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=10, verbose=1, mode='auto',\n",
    "            restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(train_generator, epochs=100, steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                        validation_data = val_generator, callbacks=[monitor],\n",
    "                        verbose = 1, validation_steps=STEP_SIZE_VALID)\n",
    "    test_generator.reset()\n",
    "    pred = model.predict(test_generator,steps=len(df_test))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44548997",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-04-18T20:42:04.529159Z",
     "iopub.status.busy": "2022-04-18T20:42:04.528247Z",
     "iopub.status.idle": "2022-04-18T23:18:33.763316Z",
     "shell.execute_reply": "2022-04-18T23:18:33.763760Z",
     "shell.execute_reply.started": "2022-04-18T19:31:39.627985Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 9389.26414,
     "end_time": "2022-04-18T23:18:33.763937",
     "exception": false,
     "start_time": "2022-04-18T20:42:04.499797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3170 validated image filenames.\n",
      "Found 793 validated image filenames.\n",
      "Found 1001 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 20:42:06.462948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:42:06.570088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:42:06.571101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:42:06.572752: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-18 20:42:06.574035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:42:06.574879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:42:06.575660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:42:08.353865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:42:08.354744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:42:08.355479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:42:08.356078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 0s 0us/step\n",
      "83697664/83683744 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 20:42:10.558846: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 20:42:15.737923: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - ETA: 0s - loss: 118291480.0000 - rmse: 10876.1885"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 20:43:36.574166: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.65GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-04-18 20:43:36.574737: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 91s 807ms/step - loss: 118291480.0000 - rmse: 10876.1885 - val_loss: 2268794624.0000 - val_rmse: 47631.8672\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 77s 773ms/step - loss: 22329128.0000 - rmse: 4725.3706 - val_loss: 2369933568.0000 - val_rmse: 48681.9648\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 77s 772ms/step - loss: 20672612.0000 - rmse: 4546.7144 - val_loss: 14751043.0000 - val_rmse: 3840.7087\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 77s 775ms/step - loss: 15212504.0000 - rmse: 3900.3210 - val_loss: 4604370.0000 - val_rmse: 2145.7795\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 77s 775ms/step - loss: 14619155.0000 - rmse: 3823.5002 - val_loss: 127077736.0000 - val_rmse: 11272.8760\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 78s 782ms/step - loss: 8041803.0000 - rmse: 2835.8074 - val_loss: 4284938.5000 - val_rmse: 2070.0093\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 77s 775ms/step - loss: 6771774.0000 - rmse: 2602.2632 - val_loss: 43947404.0000 - val_rmse: 6629.2837\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 77s 778ms/step - loss: 10368302.0000 - rmse: 3219.9849 - val_loss: 15023371.0000 - val_rmse: 3875.9993\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 77s 773ms/step - loss: 16736696.0000 - rmse: 4091.0508 - val_loss: 1194454784.0000 - val_rmse: 34560.8867\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 77s 773ms/step - loss: 19454980.0000 - rmse: 4410.7798 - val_loss: 3122074880.0000 - val_rmse: 55875.5312\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 77s 776ms/step - loss: 24056534.0000 - rmse: 4904.7461 - val_loss: 445470464.0000 - val_rmse: 21106.1719\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 77s 774ms/step - loss: 10595119.0000 - rmse: 3255.0144 - val_loss: 88949809152.0000 - val_rmse: 298244.5312\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 77s 775ms/step - loss: 22593064.0000 - rmse: 4753.2163 - val_loss: 267158192.0000 - val_rmse: 16344.9746\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 77s 774ms/step - loss: 19865602.0000 - rmse: 4457.0845 - val_loss: 2850861824.0000 - val_rmse: 53393.4609\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 77s 776ms/step - loss: 9529205.0000 - rmse: 3086.9412 - val_loss: 3650571008.0000 - val_rmse: 60419.9570\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 77s 775ms/step - loss: 8212127.5000 - rmse: 2865.6809 - val_loss: 9575680.0000 - val_rmse: 3094.4595\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Found 3260 validated image filenames.\n",
      "Found 816 validated image filenames.\n",
      "Found 1023 validated image filenames.\n",
      "Epoch 1/100\n",
      "101/101 [==============================] - 88s 833ms/step - loss: 110326392.0000 - rmse: 10503.6367 - val_loss: 1529046912.0000 - val_rmse: 39103.0312\n",
      "Epoch 2/100\n",
      "101/101 [==============================] - 80s 794ms/step - loss: 22278544.0000 - rmse: 4720.0151 - val_loss: 110709352.0000 - val_rmse: 10521.8516\n",
      "Epoch 3/100\n",
      "101/101 [==============================] - 80s 792ms/step - loss: 14706224.0000 - rmse: 3834.8694 - val_loss: 24498392.0000 - val_rmse: 4949.5850\n",
      "Epoch 4/100\n",
      "101/101 [==============================] - 81s 795ms/step - loss: 9300204.0000 - rmse: 3049.6235 - val_loss: 6881790.5000 - val_rmse: 2623.3167\n",
      "Epoch 5/100\n",
      "101/101 [==============================] - 80s 793ms/step - loss: 10422860.0000 - rmse: 3228.4456 - val_loss: 9837624.0000 - val_rmse: 3136.4988\n",
      "Epoch 6/100\n",
      "101/101 [==============================] - 81s 796ms/step - loss: 6797398.5000 - rmse: 2607.1821 - val_loss: 6085652.5000 - val_rmse: 2466.9116\n",
      "Epoch 7/100\n",
      "101/101 [==============================] - 81s 795ms/step - loss: 8245736.0000 - rmse: 2871.5391 - val_loss: 9944234.0000 - val_rmse: 3153.4480\n",
      "Epoch 8/100\n",
      "101/101 [==============================] - 81s 798ms/step - loss: 10285598.0000 - rmse: 3207.1167 - val_loss: 11865860.0000 - val_rmse: 3444.6858\n",
      "Epoch 9/100\n",
      "101/101 [==============================] - 80s 791ms/step - loss: 8071735.0000 - rmse: 2841.0798 - val_loss: 23375778.0000 - val_rmse: 4834.8506\n",
      "Epoch 10/100\n",
      "101/101 [==============================] - 81s 796ms/step - loss: 5232968.0000 - rmse: 2287.5681 - val_loss: 2170534.2500 - val_rmse: 1473.2733\n",
      "Epoch 11/100\n",
      "101/101 [==============================] - 80s 794ms/step - loss: 5148000.0000 - rmse: 2268.9204 - val_loss: 6354029.5000 - val_rmse: 2520.7200\n",
      "Epoch 12/100\n",
      "101/101 [==============================] - 80s 793ms/step - loss: 3949708.5000 - rmse: 1987.3873 - val_loss: 1624913.8750 - val_rmse: 1274.7211\n",
      "Epoch 13/100\n",
      "101/101 [==============================] - 80s 792ms/step - loss: 3266476.0000 - rmse: 1807.3395 - val_loss: 6676662.5000 - val_rmse: 2583.9238\n",
      "Epoch 14/100\n",
      "101/101 [==============================] - 81s 796ms/step - loss: 3941680.0000 - rmse: 1985.3665 - val_loss: 1744217.6250 - val_rmse: 1320.6884\n",
      "Epoch 15/100\n",
      "101/101 [==============================] - 80s 793ms/step - loss: 5557643.5000 - rmse: 2357.4656 - val_loss: 119352168.0000 - val_rmse: 10924.8418\n",
      "Epoch 16/100\n",
      "101/101 [==============================] - 80s 793ms/step - loss: 3951360.0000 - rmse: 1987.8029 - val_loss: 11439885.0000 - val_rmse: 3382.2898\n",
      "Epoch 17/100\n",
      "101/101 [==============================] - 81s 795ms/step - loss: 4536451.5000 - rmse: 2129.8948 - val_loss: 11714387.0000 - val_rmse: 3422.6287\n",
      "Epoch 18/100\n",
      "101/101 [==============================] - 81s 798ms/step - loss: 2420998.0000 - rmse: 1555.9557 - val_loss: 2287504.0000 - val_rmse: 1512.4497\n",
      "Epoch 19/100\n",
      "101/101 [==============================] - 80s 794ms/step - loss: 3113603.2500 - rmse: 1764.5405 - val_loss: 8409964.0000 - val_rmse: 2899.9939\n",
      "Epoch 20/100\n",
      "101/101 [==============================] - 80s 792ms/step - loss: 7763043.0000 - rmse: 2786.2239 - val_loss: 155080704.0000 - val_rmse: 12453.1406\n",
      "Epoch 21/100\n",
      "101/101 [==============================] - 81s 798ms/step - loss: 4248196.0000 - rmse: 2061.1152 - val_loss: 34866700.0000 - val_rmse: 5904.8032\n",
      "Epoch 22/100\n",
      "101/101 [==============================] - 81s 799ms/step - loss: 4098956.0000 - rmse: 2024.5879 - val_loss: 2984871.2500 - val_rmse: 1727.6780\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00022: early stopping\n",
      "Found 3189 validated image filenames.\n",
      "Found 798 validated image filenames.\n",
      "Found 994 validated image filenames.\n",
      "Epoch 1/100\n",
      "99/99 [==============================] - 87s 836ms/step - loss: 292224768.0000 - rmse: 17094.5820 - val_loss: 7574780416.0000 - val_rmse: 87033.2109\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 80s 802ms/step - loss: 65971488.0000 - rmse: 8122.2832 - val_loss: 713866688.0000 - val_rmse: 26718.2832\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 80s 801ms/step - loss: 41940356.0000 - rmse: 6476.1372 - val_loss: 30207130.0000 - val_rmse: 5496.1016\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 81s 813ms/step - loss: 29292862.0000 - rmse: 5412.2881 - val_loss: 116921944.0000 - val_rmse: 10813.0449\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 79s 796ms/step - loss: 32163414.0000 - rmse: 5671.2798 - val_loss: 779884800.0000 - val_rmse: 27926.4180\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 80s 804ms/step - loss: 39457724.0000 - rmse: 6281.5386 - val_loss: 31338592.0000 - val_rmse: 5598.0884\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 80s 803ms/step - loss: 20600744.0000 - rmse: 4538.8042 - val_loss: 20039912.0000 - val_rmse: 4476.5962\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 80s 806ms/step - loss: 14275887.0000 - rmse: 3778.3445 - val_loss: 56529340.0000 - val_rmse: 7518.5996\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 79s 799ms/step - loss: 16163579.0000 - rmse: 4020.3953 - val_loss: 44714688.0000 - val_rmse: 6686.9043\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 81s 812ms/step - loss: 12343960.0000 - rmse: 3513.3972 - val_loss: 50792500.0000 - val_rmse: 7126.8857\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 79s 800ms/step - loss: 8079139.0000 - rmse: 2842.3826 - val_loss: 9063827.0000 - val_rmse: 3010.6191\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 80s 802ms/step - loss: 12357295.0000 - rmse: 3515.2944 - val_loss: 20725688.0000 - val_rmse: 4552.5474\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 81s 809ms/step - loss: 6544574.5000 - rmse: 2558.2366 - val_loss: 64922000.0000 - val_rmse: 8057.4189\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 79s 797ms/step - loss: 10041203.0000 - rmse: 3168.7856 - val_loss: 5866976.0000 - val_rmse: 2422.1841\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 80s 805ms/step - loss: 9217852.0000 - rmse: 3036.0916 - val_loss: 6615768.5000 - val_rmse: 2572.1135\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 80s 805ms/step - loss: 13696696.0000 - rmse: 3700.9048 - val_loss: 31354326.0000 - val_rmse: 5599.4932\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 80s 808ms/step - loss: 11277364.0000 - rmse: 3358.1787 - val_loss: 7741410.5000 - val_rmse: 2782.3391\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 79s 799ms/step - loss: 10384401.0000 - rmse: 3222.4836 - val_loss: 7728748.0000 - val_rmse: 2780.0625\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 80s 801ms/step - loss: 5311063.5000 - rmse: 2304.5745 - val_loss: 34168452.0000 - val_rmse: 5845.3789\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 80s 804ms/step - loss: 9661502.0000 - rmse: 3108.2957 - val_loss: 57959988.0000 - val_rmse: 7613.1455\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 80s 803ms/step - loss: 12841029.0000 - rmse: 3583.4382 - val_loss: 21269034.0000 - val_rmse: 4611.8364\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 81s 807ms/step - loss: 5181603.0000 - rmse: 2276.3135 - val_loss: 23841832.0000 - val_rmse: 4882.8101\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 80s 802ms/step - loss: 7321205.5000 - rmse: 2705.7727 - val_loss: 12006743.0000 - val_rmse: 3465.0747\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 79s 795ms/step - loss: 8665213.0000 - rmse: 2943.6733 - val_loss: 104996640.0000 - val_rmse: 10246.7871\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Found 3193 validated image filenames.\n",
      "Found 799 validated image filenames.\n",
      "Found 987 validated image filenames.\n",
      "Epoch 1/100\n",
      "99/99 [==============================] - 94s 909ms/step - loss: 480193376.0000 - rmse: 21913.3145 - val_loss: 3655007232.0000 - val_rmse: 60456.6562\n",
      "Epoch 2/100\n",
      "99/99 [==============================] - 86s 867ms/step - loss: 97814856.0000 - rmse: 9890.1396 - val_loss: 480519936.0000 - val_rmse: 21920.7656\n",
      "Epoch 3/100\n",
      "99/99 [==============================] - 87s 874ms/step - loss: 59465696.0000 - rmse: 7711.4004 - val_loss: 91351424.0000 - val_rmse: 9557.7939\n",
      "Epoch 4/100\n",
      "99/99 [==============================] - 87s 870ms/step - loss: 37074948.0000 - rmse: 6088.9199 - val_loss: 182638000.0000 - val_rmse: 13514.3623\n",
      "Epoch 5/100\n",
      "99/99 [==============================] - 86s 865ms/step - loss: 21235656.0000 - rmse: 4608.2163 - val_loss: 22823882.0000 - val_rmse: 4777.4346\n",
      "Epoch 6/100\n",
      "99/99 [==============================] - 87s 874ms/step - loss: 18326032.0000 - rmse: 4280.8916 - val_loss: 22676560.0000 - val_rmse: 4761.9912\n",
      "Epoch 7/100\n",
      "99/99 [==============================] - 86s 868ms/step - loss: 38472580.0000 - rmse: 6202.6270 - val_loss: 28528282.0000 - val_rmse: 5341.1875\n",
      "Epoch 8/100\n",
      "99/99 [==============================] - 86s 868ms/step - loss: 21617178.0000 - rmse: 4649.4277 - val_loss: 388646752.0000 - val_rmse: 19714.1250\n",
      "Epoch 9/100\n",
      "99/99 [==============================] - 87s 873ms/step - loss: 21009238.0000 - rmse: 4583.5835 - val_loss: 57398800.0000 - val_rmse: 7576.1997\n",
      "Epoch 10/100\n",
      "99/99 [==============================] - 86s 869ms/step - loss: 18475442.0000 - rmse: 4298.3066 - val_loss: 25750488.0000 - val_rmse: 5074.4937\n",
      "Epoch 11/100\n",
      "99/99 [==============================] - 86s 866ms/step - loss: 40666652.0000 - rmse: 6377.0410 - val_loss: 46771072.0000 - val_rmse: 6838.9380\n",
      "Epoch 12/100\n",
      "99/99 [==============================] - 85s 860ms/step - loss: 13516746.0000 - rmse: 3676.5127 - val_loss: 12148031.0000 - val_rmse: 3485.4026\n",
      "Epoch 13/100\n",
      "99/99 [==============================] - 87s 874ms/step - loss: 13832246.0000 - rmse: 3719.1729 - val_loss: 17498776.0000 - val_rmse: 4183.1538\n",
      "Epoch 14/100\n",
      "99/99 [==============================] - 86s 870ms/step - loss: 11893365.0000 - rmse: 3448.6758 - val_loss: 39702428.0000 - val_rmse: 6300.9863\n",
      "Epoch 15/100\n",
      "99/99 [==============================] - 86s 869ms/step - loss: 12644956.0000 - rmse: 3555.9746 - val_loss: 32547862.0000 - val_rmse: 5705.0732\n",
      "Epoch 16/100\n",
      "99/99 [==============================] - 86s 862ms/step - loss: 18710176.0000 - rmse: 4325.5259 - val_loss: 118790424.0000 - val_rmse: 10899.1016\n",
      "Epoch 17/100\n",
      "99/99 [==============================] - 88s 884ms/step - loss: 10631465.0000 - rmse: 3260.5928 - val_loss: 7605228.5000 - val_rmse: 2757.7578\n",
      "Epoch 18/100\n",
      "99/99 [==============================] - 88s 881ms/step - loss: 6381163.5000 - rmse: 2526.0964 - val_loss: 10164819.0000 - val_rmse: 3188.2314\n",
      "Epoch 19/100\n",
      "99/99 [==============================] - 87s 878ms/step - loss: 5725234.0000 - rmse: 2392.7461 - val_loss: 11674445.0000 - val_rmse: 3416.7888\n",
      "Epoch 20/100\n",
      "99/99 [==============================] - 87s 872ms/step - loss: 5253487.5000 - rmse: 2292.0488 - val_loss: 9740407.0000 - val_rmse: 3120.9624\n",
      "Epoch 21/100\n",
      "99/99 [==============================] - 87s 873ms/step - loss: 5598082.0000 - rmse: 2366.0266 - val_loss: 6585404.0000 - val_rmse: 2566.2041\n",
      "Epoch 22/100\n",
      "99/99 [==============================] - 86s 865ms/step - loss: 5879689.5000 - rmse: 2424.8071 - val_loss: 8682427.0000 - val_rmse: 2946.5959\n",
      "Epoch 23/100\n",
      "99/99 [==============================] - 87s 879ms/step - loss: 5541189.5000 - rmse: 2353.9731 - val_loss: 11133050.0000 - val_rmse: 3336.6226\n",
      "Epoch 24/100\n",
      "99/99 [==============================] - 88s 883ms/step - loss: 4150994.0000 - rmse: 2037.3988 - val_loss: 16390384.0000 - val_rmse: 4048.5039\n",
      "Epoch 25/100\n",
      "99/99 [==============================] - 87s 875ms/step - loss: 12021001.0000 - rmse: 3467.1316 - val_loss: 9364049.0000 - val_rmse: 3060.0735\n",
      "Epoch 26/100\n",
      "99/99 [==============================] - 88s 881ms/step - loss: 9286443.0000 - rmse: 3047.3665 - val_loss: 5252256.5000 - val_rmse: 2291.7803\n",
      "Epoch 27/100\n",
      "99/99 [==============================] - 88s 888ms/step - loss: 14656014.0000 - rmse: 3828.3174 - val_loss: 39929320.0000 - val_rmse: 6318.9653\n",
      "Epoch 28/100\n",
      "99/99 [==============================] - 88s 881ms/step - loss: 8739800.0000 - rmse: 2956.3152 - val_loss: 12249833.0000 - val_rmse: 3499.9761\n",
      "Epoch 29/100\n",
      "99/99 [==============================] - 86s 869ms/step - loss: 9605690.0000 - rmse: 3099.3047 - val_loss: 37400232.0000 - val_rmse: 6115.5728\n",
      "Epoch 30/100\n",
      "99/99 [==============================] - 87s 874ms/step - loss: 6794775.5000 - rmse: 2606.6790 - val_loss: 7530356.0000 - val_rmse: 2744.1494\n",
      "Epoch 31/100\n",
      "99/99 [==============================] - 88s 882ms/step - loss: 7099954.0000 - rmse: 2664.5740 - val_loss: 9157478.0000 - val_rmse: 3026.1326\n",
      "Epoch 32/100\n",
      "99/99 [==============================] - 87s 877ms/step - loss: 4207394.5000 - rmse: 2051.1934 - val_loss: 25530574.0000 - val_rmse: 5052.7788\n",
      "Epoch 33/100\n",
      "99/99 [==============================] - 87s 875ms/step - loss: 7126208.0000 - rmse: 2669.4958 - val_loss: 12794704.0000 - val_rmse: 3576.9685\n",
      "Epoch 34/100\n",
      "99/99 [==============================] - 88s 885ms/step - loss: 5793316.0000 - rmse: 2406.9309 - val_loss: 5435972.0000 - val_rmse: 2331.5171\n",
      "Epoch 35/100\n",
      "99/99 [==============================] - 87s 877ms/step - loss: 10841414.0000 - rmse: 3292.6304 - val_loss: 6592739.5000 - val_rmse: 2567.6331\n",
      "Epoch 36/100\n",
      "99/99 [==============================] - 86s 870ms/step - loss: 8575965.0000 - rmse: 2928.4749 - val_loss: 14296443.0000 - val_rmse: 3781.0637\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00036: early stopping\n"
     ]
    }
   ],
   "source": [
    "pred0 = get_model(df_train[df_train['size_cat'] == 0], df_test[df_test['size_cat'] == 0])\n",
    "pred1 = get_model(df_train[df_train['size_cat'] == 1], df_test[df_test['size_cat'] == 1])\n",
    "pred2 = get_model(df_train[df_train['size_cat'] == 2], df_test[df_test['size_cat'] == 2])\n",
    "pred3 = get_model(df_train[df_train['size_cat'] == 3], df_test[df_test['size_cat'] == 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a4a963",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-04-18T23:18:40.318481Z",
     "iopub.status.busy": "2022-04-18T23:18:40.317207Z",
     "iopub.status.idle": "2022-04-18T23:18:40.319268Z",
     "shell.execute_reply": "2022-04-18T23:18:40.319757Z",
     "shell.execute_reply.started": "2022-04-18T20:31:23.954458Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 3.143255,
     "end_time": "2022-04-18T23:18:40.319913",
     "exception": false,
     "start_time": "2022-04-18T23:18:37.176658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_submit = pd.DataFrame()\n",
    "# id_list = df_test[df_test['size_cat'] == 0].id.tolist() + df_test[df_test['size_cat'] == 1].id.tolist()\n",
    "# pred_list = list(pred0.flatten()) + list(pred1.flatten())\n",
    "# df_submit['id'] = id_list\n",
    "# df_submit['distance'] = pred_list\n",
    "# df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4064ad67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T23:18:46.886166Z",
     "iopub.status.busy": "2022-04-18T23:18:46.885329Z",
     "iopub.status.idle": "2022-04-18T23:18:46.899467Z",
     "shell.execute_reply": "2022-04-18T23:18:46.899031Z",
     "shell.execute_reply.started": "2022-04-18T20:28:34.284650Z"
    },
    "papermill": {
     "duration": 3.209511,
     "end_time": "2022-04-18T23:18:46.899627",
     "exception": false,
     "start_time": "2022-04-18T23:18:43.690116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_submit = pd.DataFrame()\n",
    "id_list = df_test[df_test['size_cat'] == 0].id.tolist() + df_test[df_test['size_cat'] == 1].id.tolist() + df_test[df_test['size_cat'] == 2].id.tolist() + df_test[df_test['size_cat'] == 3].id.tolist()\n",
    "pred_list = list(pred0.flatten()) + list(pred1.flatten()) + list(pred2.flatten()) + list(pred3.flatten())\n",
    "df_submit['id'] = id_list\n",
    "df_submit['distance'] = pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de25f381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T23:18:54.120455Z",
     "iopub.status.busy": "2022-04-18T23:18:54.118274Z",
     "iopub.status.idle": "2022-04-18T23:18:54.134788Z",
     "shell.execute_reply": "2022-04-18T23:18:54.134247Z",
     "shell.execute_reply.started": "2022-04-18T20:28:34.287000Z"
    },
    "papermill": {
     "duration": 3.252185,
     "end_time": "2022-04-18T23:18:54.134921",
     "exception": false,
     "start_time": "2022-04-18T23:18:50.882736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_submit.to_csv(\"submit.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4ac9f60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T23:19:00.746823Z",
     "iopub.status.busy": "2022-04-18T23:19:00.745970Z",
     "iopub.status.idle": "2022-04-18T23:19:00.748333Z",
     "shell.execute_reply": "2022-04-18T23:19:00.747831Z",
     "shell.execute_reply.started": "2022-04-18T20:28:34.289413Z"
    },
    "papermill": {
     "duration": 3.434286,
     "end_time": "2022-04-18T23:19:00.748447",
     "exception": false,
     "start_time": "2022-04-18T23:18:57.314161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# id_list = df_test[df_test['size_cat'] == 0].id.tolist() + df_test[df_test['size_cat'] == 1].id.tolist() + df_test[df_test['size_cat'] == 2].id.tolist() + df_test[df_test['size_cat'] == 3].id.tolist()\n",
    "# len(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb50ab18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T23:19:07.090250Z",
     "iopub.status.busy": "2022-04-18T23:19:07.089708Z",
     "iopub.status.idle": "2022-04-18T23:19:07.093386Z",
     "shell.execute_reply": "2022-04-18T23:19:07.092989Z",
     "shell.execute_reply.started": "2022-04-18T20:28:34.291310Z"
    },
    "papermill": {
     "duration": 3.150921,
     "end_time": "2022-04-18T23:19:07.093499",
     "exception": false,
     "start_time": "2022-04-18T23:19:03.942578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "# import numpy as np\n",
    "# plt.rcParams['figure.figsize'] = (15,9)\n",
    "# def select_blue(image):\n",
    "#     # Grab the x and y size and make a copy of the image\n",
    "#     ysize = image.shape[0]\n",
    "#     xsize = image.shape[1]\n",
    "#     color_select = np.copy(image)\n",
    "\n",
    "#     # Define color selection criteria\n",
    "#     ###### MODIFY THESE VARIABLES TO MAKE YOUR COLOR SELECTION\n",
    "#     red_threshold = -1\n",
    "#     green_threshold = -1\n",
    "#     blue_threshold = 135\n",
    "#     ######\n",
    "\n",
    "#     rgb_threshold = [red_threshold, green_threshold, blue_threshold]\n",
    "\n",
    "#     # Do a boolean or with the \"|\" character to identify\n",
    "#     # pixels below the thresholds\n",
    "#     thresholds = (image[:,:,0] < rgb_threshold[0]) \\\n",
    "#                 | (image[:,:,1] < rgb_threshold[1]) \\\n",
    "#                 | (image[:,:,2] < rgb_threshold[2])\n",
    "#     color_select[thresholds] = [0,0,0]\n",
    "#     image = color_select\n",
    "    \n",
    "#     return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a681e402",
   "metadata": {
    "papermill": {
     "duration": 3.203601,
     "end_time": "2022-04-18T23:19:13.832289",
     "exception": false,
     "start_time": "2022-04-18T23:19:10.628688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We want to use early stopping.  To do this, we need a validation set.  We will break the data into 80 percent test data and 20 validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3a854cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T23:19:20.410440Z",
     "iopub.status.busy": "2022-04-18T23:19:20.409517Z",
     "iopub.status.idle": "2022-04-18T23:19:20.411393Z",
     "shell.execute_reply": "2022-04-18T23:19:20.412180Z",
     "shell.execute_reply.started": "2022-04-18T20:28:34.293613Z"
    },
    "papermill": {
     "duration": 3.323793,
     "end_time": "2022-04-18T23:19:20.412375",
     "exception": false,
     "start_time": "2022-04-18T23:19:17.088582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAIN_PCT = 0.9\n",
    "# TRAIN_CUT = int(len(df_train) * TRAIN_PCT)\n",
    "\n",
    "# df_train_cut = df_train[0:TRAIN_CUT]\n",
    "# df_validate_cut = df_train[TRAIN_CUT:]\n",
    "\n",
    "# print(f\"Training size: {len(df_train_cut)}\")\n",
    "# print(f\"Validate size: {len(df_validate_cut)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a2cc74",
   "metadata": {
    "papermill": {
     "duration": 3.313583,
     "end_time": "2022-04-18T23:19:27.404897",
     "exception": false,
     "start_time": "2022-04-18T23:19:24.091314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we create the generators that will provide the images to the neural network as it is trained.  We normalize the images so that the RGB colors between 0-255 become ratios between 0 and 1.  We also use the **flow_from_dataframe** generator to connect the Pandas dataframe to the actual image files. We see here a straightforward implementation; you might also wish to use some of the image transformations provided by the data generator.\n",
    "\n",
    "The **HEIGHT** and **WIDTH** constants specify the dimensions that the image will be scaled (or expanded) to. It is probably not a good idea to expand the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99af1e8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T23:19:33.923090Z",
     "iopub.status.busy": "2022-04-18T23:19:33.922030Z",
     "iopub.status.idle": "2022-04-18T23:19:33.923914Z",
     "shell.execute_reply": "2022-04-18T23:19:33.924378Z",
     "shell.execute_reply.started": "2022-04-18T20:28:34.295679Z"
    },
    "papermill": {
     "duration": 3.378929,
     "end_time": "2022-04-18T23:19:33.924557",
     "exception": false,
     "start_time": "2022-04-18T23:19:30.545628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def line_detect_possible(img):\n",
    "#     L = len(img)\n",
    "#     H = len(img[0])\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)\n",
    "#     gray = gray.astype(np.uint8)\n",
    "#     edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "    \n",
    "#     lines = cv2.HoughLinesP(edges, 1, np.pi/720, 30, minLineLength=20, maxLineGap=8)\n",
    "#     img = np.zeros( ( L, H, 3), np.uint8 )\n",
    "#     for line in lines:\n",
    "#         x1, y1, x2, y2 = line[0]\n",
    "#         cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "#     return img.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc3da263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T23:19:40.316356Z",
     "iopub.status.busy": "2022-04-18T23:19:40.315456Z",
     "iopub.status.idle": "2022-04-18T23:19:40.317562Z",
     "shell.execute_reply": "2022-04-18T23:19:40.317964Z",
     "shell.execute_reply.started": "2022-04-18T20:28:34.297960Z"
    },
    "papermill": {
     "duration": 3.161964,
     "end_time": "2022-04-18T23:19:40.318122",
     "exception": false,
     "start_time": "2022-04-18T23:19:37.156158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import keras_preprocessing\n",
    "# from keras_preprocessing import image\n",
    "# from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# HEIGHT = 299\n",
    "# WIDTH = 299\n",
    "\n",
    "# training_datagen = ImageDataGenerator(\n",
    "#   rescale = 1./255,\n",
    "#   horizontal_flip=True,\n",
    "#   #vertical_flip=True,\n",
    "#   fill_mode='nearest'\n",
    "# #   preprocessing_function = select_blue\n",
    "# )\n",
    "\n",
    "\n",
    "# train_generator = training_datagen.flow_from_dataframe(\n",
    "#         dataframe=df_train_cut,\n",
    "#         directory=PATH,\n",
    "#         x_col=\"filename\",\n",
    "#         y_col=\"distance\",\n",
    "#         target_size=(HEIGHT, WIDTH),\n",
    "#         batch_size=32, # Keeping the training batch size small USUALLY increases performance\n",
    "#         class_mode='raw')\n",
    "\n",
    "# validation_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "# #     preprocessing_function = select_blu\n",
    "# )\n",
    "\n",
    "# val_generator = validation_datagen.flow_from_dataframe(\n",
    "#         dataframe=df_validate_cut,\n",
    "#         directory=PATH,\n",
    "#         x_col=\"filename\",\n",
    "#         y_col=\"distance\",\n",
    "#         target_size=(HEIGHT, WIDTH),\n",
    "#         batch_size=256, # Make the validation batch size as large as you have memory for\n",
    "#         class_mode='raw')\n",
    "\n",
    "\n",
    "# test_datagen = ImageDataGenerator(\n",
    "#     rescale = 1./255\n",
    "# #     preprocessing_function = select_blue\n",
    "# )\n",
    "\n",
    "# test_generator = validation_datagen.flow_from_dataframe(\n",
    "#         dataframe=df_test,\n",
    "#         directory=PATH,\n",
    "#         x_col=\"filename\",\n",
    "#         batch_size=1,\n",
    "#         shuffle=False,\n",
    "#         target_size=(HEIGHT, WIDTH),\n",
    "#         class_mode=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b56e0e1",
   "metadata": {
    "papermill": {
     "duration": 3.246557,
     "end_time": "2022-04-18T23:19:46.976300",
     "exception": false,
     "start_time": "2022-04-18T23:19:43.729743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transfer Learning\n",
    "\n",
    "We will now use a Xception neural network as a basis for our neural network.  We will redefine both the input shape and output of the ResNet model, so we will not transfer the weights.  Since we redefine the input; the weights are of minimal value.  We begin by loading, from Keras, the Xception network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b89e69a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T23:19:53.748972Z",
     "iopub.status.busy": "2022-04-18T23:19:53.747820Z",
     "iopub.status.idle": "2022-04-18T23:19:53.755226Z",
     "shell.execute_reply": "2022-04-18T23:19:53.755833Z",
     "shell.execute_reply.started": "2022-04-18T20:28:34.299827Z"
    },
    "papermill": {
     "duration": 3.688582,
     "end_time": "2022-04-18T23:19:53.756148",
     "exception": false,
     "start_time": "2022-04-18T23:19:50.067566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import Xception\n",
    "# from tensorflow.keras.layers import Input\n",
    "# from tensorflow.keras.models import Sequential\n",
    "\n",
    "# input_tensor = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "\n",
    "# base_model = Xception(\n",
    "#     include_top=False, weights=None, input_tensor=input_tensor,\n",
    "#     input_shape=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5900e53a",
   "metadata": {
    "papermill": {
     "duration": 3.118279,
     "end_time": "2022-04-18T23:20:00.397860",
     "exception": false,
     "start_time": "2022-04-18T23:19:57.279581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we must add a few layers to the end of the neural network so that it becomes a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a8d559f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T23:20:07.127559Z",
     "iopub.status.busy": "2022-04-18T23:20:07.126652Z",
     "iopub.status.idle": "2022-04-18T23:20:07.128987Z",
     "shell.execute_reply": "2022-04-18T23:20:07.128469Z",
     "shell.execute_reply.started": "2022-04-18T20:28:34.301945Z"
    },
    "papermill": {
     "duration": 3.635288,
     "end_time": "2022-04-18T23:20:07.129108",
     "exception": false,
     "start_time": "2022-04-18T23:20:03.493820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# x=base_model.output\n",
    "# x=GlobalAveragePooling2D()(x)\n",
    "# x=Dense(2048,activation='relu')(x) \n",
    "# x=Dense(2048,activation='relu')(x) \n",
    "# model=Model(inputs=base_model.input,outputs=Dense(1)(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53143c24",
   "metadata": {
    "papermill": {
     "duration": 3.1643,
     "end_time": "2022-04-18T23:20:13.372776",
     "exception": false,
     "start_time": "2022-04-18T23:20:10.208476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we train just like before, the only difference is that we do not define the entire neural network here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c56eb781",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T23:20:20.107897Z",
     "iopub.status.busy": "2022-04-18T23:20:20.107028Z",
     "iopub.status.idle": "2022-04-18T23:20:20.109507Z",
     "shell.execute_reply": "2022-04-18T23:20:20.109112Z",
     "shell.execute_reply.started": "2022-04-18T20:28:34.303909Z"
    },
    "papermill": {
     "duration": 3.234855,
     "end_time": "2022-04-18T23:20:20.109657",
     "exception": false,
     "start_time": "2022-04-18T23:20:16.874802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "# # Important, calculate a valid step size for the validation dataset\n",
    "# STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
    "\n",
    "# model.compile(loss = 'mean_squared_error', optimizer='adam', metrics=[RootMeanSquaredError(name=\"rmse\")])\n",
    "# monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=10, verbose=1, mode='auto',\n",
    "#         restore_best_weights=True)\n",
    "\n",
    "# history = model.fit(train_generator, epochs=100, steps_per_epoch=50, \n",
    "#                     validation_data = val_generator, callbacks=[monitor],\n",
    "#                     verbose = 1, validation_steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dec9737d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T23:20:27.332959Z",
     "iopub.status.busy": "2022-04-18T23:20:27.332028Z",
     "iopub.status.idle": "2022-04-18T23:20:27.334041Z",
     "shell.execute_reply": "2022-04-18T23:20:27.334457Z",
     "shell.execute_reply.started": "2022-04-18T20:28:34.305287Z"
    },
    "papermill": {
     "duration": 4.07587,
     "end_time": "2022-04-18T23:20:27.334619",
     "exception": false,
     "start_time": "2022-04-18T23:20:23.258749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_generator.reset()\n",
    "# pred = model.predict(test_generator,steps=len(df_test))\n",
    "\n",
    "# df_submit = pd.DataFrame({'id':df_test['id'],'distance':pred.flatten()})\n",
    "# df_submit.to_csv(\"submit.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e16423",
   "metadata": {
    "papermill": {
     "duration": 3.143279,
     "end_time": "2022-04-18T23:20:33.696056",
     "exception": false,
     "start_time": "2022-04-18T23:20:30.552777",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9783.872603,
   "end_time": "2022-04-18T23:20:40.403287",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-18T20:37:36.530684",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
