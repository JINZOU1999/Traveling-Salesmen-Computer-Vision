{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef869b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:51:01.989680Z",
     "iopub.status.busy": "2022-04-16T21:51:01.988810Z",
     "iopub.status.idle": "2022-04-16T21:51:07.600861Z",
     "shell.execute_reply": "2022-04-16T21:51:07.601336Z",
     "shell.execute_reply.started": "2022-04-16T21:49:41.486125Z"
    },
    "papermill": {
     "duration": 5.631226,
     "end_time": "2022-04-16T21:51:07.601625",
     "exception": false,
     "start_time": "2022-04-16T21:51:01.970399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import keras\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "PATH = \"/kaggle/input/tsp-cv\"\n",
    "PATH_TRAIN = os.path.join(PATH, \"train.csv\")\n",
    "PATH_TEST = os.path.join(PATH , 'test.csv')\n",
    "df_train = pd.read_csv(PATH_TRAIN)\n",
    "df_test = pd.read_csv(PATH_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acbec6d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:51:07.619626Z",
     "iopub.status.busy": "2022-04-16T21:51:07.618789Z",
     "iopub.status.idle": "2022-04-16T21:51:07.621191Z",
     "shell.execute_reply": "2022-04-16T21:51:07.620761Z",
     "shell.execute_reply.started": "2022-04-16T21:49:46.847790Z"
    },
    "papermill": {
     "duration": 0.012926,
     "end_time": "2022-04-16T21:51:07.621296",
     "exception": false,
     "start_time": "2022-04-16T21:51:07.608370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_PCT = 0.78\n",
    "TRAIN_CUT = int(len(df_train) * TRAIN_PCT)\n",
    "\n",
    "df_train_cut = df_train[0:TRAIN_CUT]\n",
    "df_validate_cut = df_train[TRAIN_CUT:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16fcb511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:51:07.640581Z",
     "iopub.status.busy": "2022-04-16T21:51:07.635219Z",
     "iopub.status.idle": "2022-04-16T21:51:16.094289Z",
     "shell.execute_reply": "2022-04-16T21:51:16.093836Z",
     "shell.execute_reply.started": "2022-04-16T21:49:46.854325Z"
    },
    "papermill": {
     "duration": 8.467499,
     "end_time": "2022-04-16T21:51:16.094406",
     "exception": false,
     "start_time": "2022-04-16T21:51:07.626907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12494 validated image filenames.\n",
      "Found 3524 validated image filenames.\n",
      "Found 4005 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "WIDTH = 299\n",
    "HEIGHT = 299\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "  rescale = 1./255,\n",
    "  horizontal_flip=True,\n",
    "  #vertical_flip=True,\n",
    "  fill_mode='nearest')\n",
    "\n",
    "train_generator = training_datagen.flow_from_dataframe(\n",
    "        dataframe=df_train_cut,\n",
    "        directory=PATH,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"distance\",\n",
    "        target_size=(HEIGHT, WIDTH),\n",
    "        batch_size=32, # Keeping the training batch size small USUALLY increases performance\n",
    "        class_mode='raw')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "val_generator = validation_datagen.flow_from_dataframe(\n",
    "        dataframe=df_validate_cut,\n",
    "        directory=PATH,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"distance\",\n",
    "        target_size=(HEIGHT, WIDTH),\n",
    "        batch_size=256, # Make the validation batch size as large as you have memory for\n",
    "        class_mode='raw')\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_generator = validation_datagen.flow_from_dataframe(\n",
    "        dataframe=df_test,\n",
    "        directory=PATH,\n",
    "        x_col=\"filename\",\n",
    "    \n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        target_size=(HEIGHT, WIDTH),\n",
    "        class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fed1e58f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:51:16.121688Z",
     "iopub.status.busy": "2022-04-16T21:51:16.112356Z",
     "iopub.status.idle": "2022-04-16T23:11:33.935202Z",
     "shell.execute_reply": "2022-04-16T23:11:33.933889Z"
    },
    "papermill": {
     "duration": 4817.83346,
     "end_time": "2022-04-16T23:11:33.935329",
     "exception": false,
     "start_time": "2022-04-16T21:51:16.101869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 21:51:16.203392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 21:51:16.298974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 21:51:16.299794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 21:51:16.301304: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-16 21:51:16.302219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 21:51:16.302955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 21:51:16.303624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 21:51:18.147372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 21:51:18.148259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 21:51:18.148940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-16 21:51:18.149547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2022-04-16 21:51:19.081456: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 21:51:20.880830: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 82s 2s/step - loss: 1059807040.0000 - rmse: 32554.6777 - val_loss: 986088832.0000 - val_rmse: 31402.0508\n",
      "Epoch 2/120\n",
      "50/50 [==============================] - 54s 1s/step - loss: 891568896.0000 - rmse: 29859.1504 - val_loss: 984724480.0000 - val_rmse: 31380.3203\n",
      "Epoch 3/120\n",
      "50/50 [==============================] - 53s 1s/step - loss: 790001280.0000 - rmse: 28106.9609 - val_loss: 898505856.0000 - val_rmse: 29975.0879\n",
      "Epoch 4/120\n",
      "50/50 [==============================] - 53s 1s/step - loss: 762667776.0000 - rmse: 27616.4395 - val_loss: 760849664.0000 - val_rmse: 27583.5039\n",
      "Epoch 5/120\n",
      "50/50 [==============================] - 52s 1s/step - loss: 588748032.0000 - rmse: 24264.1309 - val_loss: 587784896.0000 - val_rmse: 24244.2754\n",
      "Epoch 6/120\n",
      "50/50 [==============================] - 52s 1s/step - loss: 457812960.0000 - rmse: 21396.5645 - val_loss: 441115104.0000 - val_rmse: 21002.7402\n",
      "Epoch 7/120\n",
      "50/50 [==============================] - 51s 1s/step - loss: 310031904.0000 - rmse: 17607.7227 - val_loss: 353636544.0000 - val_rmse: 18805.2266\n",
      "Epoch 8/120\n",
      "50/50 [==============================] - 50s 1s/step - loss: 283045152.0000 - rmse: 16823.9453 - val_loss: 349602976.0000 - val_rmse: 18697.6738\n",
      "Epoch 9/120\n",
      "50/50 [==============================] - 50s 1s/step - loss: 302776288.0000 - rmse: 17400.4688 - val_loss: 318788128.0000 - val_rmse: 17854.6387\n",
      "Epoch 10/120\n",
      "50/50 [==============================] - 50s 1s/step - loss: 270627840.0000 - rmse: 16450.7695 - val_loss: 319796256.0000 - val_rmse: 17882.8477\n",
      "Epoch 11/120\n",
      "50/50 [==============================] - 50s 1s/step - loss: 296727584.0000 - rmse: 17225.7832 - val_loss: 305352320.0000 - val_rmse: 17474.3340\n",
      "Epoch 12/120\n",
      "50/50 [==============================] - 49s 990ms/step - loss: 252478896.0000 - rmse: 15889.5850 - val_loss: 291101632.0000 - val_rmse: 17061.7012\n",
      "Epoch 13/120\n",
      "50/50 [==============================] - 49s 995ms/step - loss: 243926144.0000 - rmse: 15618.1348 - val_loss: 287793216.0000 - val_rmse: 16964.4688\n",
      "Epoch 14/120\n",
      "50/50 [==============================] - 48s 978ms/step - loss: 266413328.0000 - rmse: 16322.1729 - val_loss: 274078560.0000 - val_rmse: 16555.3184\n",
      "Epoch 15/120\n",
      "50/50 [==============================] - 50s 1000ms/step - loss: 232625136.0000 - rmse: 15252.0537 - val_loss: 275064096.0000 - val_rmse: 16585.0566\n",
      "Epoch 16/120\n",
      "50/50 [==============================] - 48s 979ms/step - loss: 257727360.0000 - rmse: 16053.8896 - val_loss: 251752592.0000 - val_rmse: 15866.7129\n",
      "Epoch 17/120\n",
      "50/50 [==============================] - 48s 974ms/step - loss: 244518672.0000 - rmse: 15637.0928 - val_loss: 246965520.0000 - val_rmse: 15715.1367\n",
      "Epoch 18/120\n",
      "50/50 [==============================] - 48s 971ms/step - loss: 189142672.0000 - rmse: 13752.9150 - val_loss: 247907680.0000 - val_rmse: 15745.0840\n",
      "Epoch 19/120\n",
      "50/50 [==============================] - 48s 971ms/step - loss: 247323232.0000 - rmse: 15726.5137 - val_loss: 232930048.0000 - val_rmse: 15262.0459\n",
      "Epoch 20/120\n",
      "50/50 [==============================] - 48s 976ms/step - loss: 216146880.0000 - rmse: 14701.9346 - val_loss: 227942080.0000 - val_rmse: 15097.7510\n",
      "Epoch 21/120\n",
      "50/50 [==============================] - 47s 951ms/step - loss: 232362304.0000 - rmse: 15243.4346 - val_loss: 220314960.0000 - val_rmse: 14843.0107\n",
      "Epoch 22/120\n",
      "50/50 [==============================] - 48s 972ms/step - loss: 210520640.0000 - rmse: 14509.3291 - val_loss: 217823648.0000 - val_rmse: 14758.8496\n",
      "Epoch 23/120\n",
      "50/50 [==============================] - 48s 966ms/step - loss: 203833504.0000 - rmse: 14277.0273 - val_loss: 218455696.0000 - val_rmse: 14780.2471\n",
      "Epoch 24/120\n",
      "50/50 [==============================] - 48s 972ms/step - loss: 182323936.0000 - rmse: 13502.7383 - val_loss: 213966960.0000 - val_rmse: 14627.6094\n",
      "Epoch 25/120\n",
      "50/50 [==============================] - 48s 970ms/step - loss: 189904752.0000 - rmse: 13780.5938 - val_loss: 207422816.0000 - val_rmse: 14402.1807\n",
      "Epoch 26/120\n",
      "50/50 [==============================] - 48s 973ms/step - loss: 215541472.0000 - rmse: 14681.3311 - val_loss: 193631248.0000 - val_rmse: 13915.1445\n",
      "Epoch 27/120\n",
      "50/50 [==============================] - 48s 964ms/step - loss: 171386832.0000 - rmse: 13091.4795 - val_loss: 202676256.0000 - val_rmse: 14236.4414\n",
      "Epoch 28/120\n",
      "50/50 [==============================] - 48s 964ms/step - loss: 190454576.0000 - rmse: 13800.5283 - val_loss: 195985344.0000 - val_rmse: 13999.4766\n",
      "Epoch 29/120\n",
      "50/50 [==============================] - 48s 969ms/step - loss: 140437888.0000 - rmse: 11850.6494 - val_loss: 190639936.0000 - val_rmse: 13807.2422\n",
      "Epoch 30/120\n",
      "50/50 [==============================] - 48s 965ms/step - loss: 167474848.0000 - rmse: 12941.2070 - val_loss: 202512896.0000 - val_rmse: 14230.7021\n",
      "Epoch 31/120\n",
      "50/50 [==============================] - 48s 967ms/step - loss: 155059040.0000 - rmse: 12452.2705 - val_loss: 197494976.0000 - val_rmse: 14053.2910\n",
      "Epoch 32/120\n",
      "50/50 [==============================] - 48s 975ms/step - loss: 145395184.0000 - rmse: 12057.9922 - val_loss: 192002736.0000 - val_rmse: 13856.5049\n",
      "Epoch 33/120\n",
      "50/50 [==============================] - 48s 969ms/step - loss: 161025440.0000 - rmse: 12689.5801 - val_loss: 183234320.0000 - val_rmse: 13536.4072\n",
      "Epoch 34/120\n",
      "50/50 [==============================] - 48s 973ms/step - loss: 175447744.0000 - rmse: 13245.6689 - val_loss: 176706448.0000 - val_rmse: 13293.0977\n",
      "Epoch 35/120\n",
      "50/50 [==============================] - 48s 962ms/step - loss: 154755664.0000 - rmse: 12440.0830 - val_loss: 169053520.0000 - val_rmse: 13002.0586\n",
      "Epoch 36/120\n",
      "50/50 [==============================] - 48s 971ms/step - loss: 160778656.0000 - rmse: 12679.8525 - val_loss: 182509680.0000 - val_rmse: 13509.6143\n",
      "Epoch 37/120\n",
      "50/50 [==============================] - 48s 973ms/step - loss: 138106752.0000 - rmse: 11751.8828 - val_loss: 179875360.0000 - val_rmse: 13411.7617\n",
      "Epoch 38/120\n",
      "50/50 [==============================] - 48s 968ms/step - loss: 105245848.0000 - rmse: 10258.9395 - val_loss: 182799440.0000 - val_rmse: 13520.3340\n",
      "Epoch 39/120\n",
      "50/50 [==============================] - 48s 973ms/step - loss: 145414624.0000 - rmse: 12058.7988 - val_loss: 168835440.0000 - val_rmse: 12993.6689\n",
      "Epoch 40/120\n",
      "50/50 [==============================] - 48s 962ms/step - loss: 149894128.0000 - rmse: 12243.1260 - val_loss: 161807520.0000 - val_rmse: 12720.3584\n",
      "Epoch 41/120\n",
      "50/50 [==============================] - 49s 984ms/step - loss: 136470288.0000 - rmse: 11682.0498 - val_loss: 162620960.0000 - val_rmse: 12752.2920\n",
      "Epoch 42/120\n",
      "50/50 [==============================] - 48s 959ms/step - loss: 112416576.0000 - rmse: 10602.6680 - val_loss: 162769296.0000 - val_rmse: 12758.1074\n",
      "Epoch 43/120\n",
      "50/50 [==============================] - 48s 967ms/step - loss: 131336256.0000 - rmse: 11460.2031 - val_loss: 176029376.0000 - val_rmse: 13267.6064\n",
      "Epoch 44/120\n",
      "50/50 [==============================] - 48s 967ms/step - loss: 113241200.0000 - rmse: 10641.4844 - val_loss: 185745600.0000 - val_rmse: 13628.8516\n",
      "Epoch 45/120\n",
      "50/50 [==============================] - 48s 961ms/step - loss: 135858112.0000 - rmse: 11655.8184 - val_loss: 163799584.0000 - val_rmse: 12798.4209\n",
      "Epoch 46/120\n",
      "50/50 [==============================] - 48s 974ms/step - loss: 124254632.0000 - rmse: 11146.9561 - val_loss: 170411360.0000 - val_rmse: 13054.1699\n",
      "Epoch 47/120\n",
      "50/50 [==============================] - 48s 972ms/step - loss: 128606464.0000 - rmse: 11340.4785 - val_loss: 158237600.0000 - val_rmse: 12579.2529\n",
      "Epoch 48/120\n",
      "50/50 [==============================] - 47s 958ms/step - loss: 145391728.0000 - rmse: 12057.8496 - val_loss: 160799648.0000 - val_rmse: 12680.6797\n",
      "Epoch 49/120\n",
      "50/50 [==============================] - 49s 981ms/step - loss: 123028152.0000 - rmse: 11091.8057 - val_loss: 171370608.0000 - val_rmse: 13090.8594\n",
      "Epoch 50/120\n",
      "50/50 [==============================] - 47s 961ms/step - loss: 149197024.0000 - rmse: 12214.6230 - val_loss: 149963248.0000 - val_rmse: 12245.9482\n",
      "Epoch 51/120\n",
      "50/50 [==============================] - 47s 959ms/step - loss: 131033856.0000 - rmse: 11447.0020 - val_loss: 158593056.0000 - val_rmse: 12593.3730\n",
      "Epoch 52/120\n",
      "50/50 [==============================] - 48s 962ms/step - loss: 139731120.0000 - rmse: 11820.7920 - val_loss: 155750944.0000 - val_rmse: 12480.0215\n",
      "Epoch 53/120\n",
      "50/50 [==============================] - 47s 959ms/step - loss: 144767104.0000 - rmse: 12031.9199 - val_loss: 159622304.0000 - val_rmse: 12634.1719\n",
      "Epoch 54/120\n",
      "50/50 [==============================] - 49s 980ms/step - loss: 117308640.0000 - rmse: 10830.9111 - val_loss: 163397328.0000 - val_rmse: 12782.6963\n",
      "Epoch 55/120\n",
      "50/50 [==============================] - 48s 963ms/step - loss: 133956136.0000 - rmse: 11573.9424 - val_loss: 160943584.0000 - val_rmse: 12686.3545\n",
      "Epoch 56/120\n",
      "50/50 [==============================] - 48s 969ms/step - loss: 126843648.0000 - rmse: 11262.4883 - val_loss: 148975664.0000 - val_rmse: 12205.5586\n",
      "Epoch 57/120\n",
      "50/50 [==============================] - 48s 966ms/step - loss: 116606432.0000 - rmse: 10798.4463 - val_loss: 154195952.0000 - val_rmse: 12417.5664\n",
      "Epoch 58/120\n",
      "50/50 [==============================] - 48s 971ms/step - loss: 121726024.0000 - rmse: 11032.9521 - val_loss: 160385504.0000 - val_rmse: 12664.3398\n",
      "Epoch 59/120\n",
      "50/50 [==============================] - 48s 964ms/step - loss: 108373976.0000 - rmse: 10410.2822 - val_loss: 154695504.0000 - val_rmse: 12437.6650\n",
      "Epoch 60/120\n",
      "50/50 [==============================] - 49s 994ms/step - loss: 121314624.0000 - rmse: 11014.2920 - val_loss: 159790752.0000 - val_rmse: 12640.8369\n",
      "Epoch 61/120\n",
      "50/50 [==============================] - 48s 973ms/step - loss: 128298520.0000 - rmse: 11326.8936 - val_loss: 149664880.0000 - val_rmse: 12233.7598\n",
      "Epoch 62/120\n",
      "50/50 [==============================] - 48s 977ms/step - loss: 106943448.0000 - rmse: 10341.3467 - val_loss: 153133872.0000 - val_rmse: 12374.7275\n",
      "Epoch 63/120\n",
      "50/50 [==============================] - 48s 969ms/step - loss: 141165424.0000 - rmse: 11881.3057 - val_loss: 149438352.0000 - val_rmse: 12224.4980\n",
      "Epoch 64/120\n",
      "50/50 [==============================] - 49s 984ms/step - loss: 140718848.0000 - rmse: 11862.4971 - val_loss: 143218976.0000 - val_rmse: 11967.4131\n",
      "Epoch 65/120\n",
      "50/50 [==============================] - 48s 970ms/step - loss: 134476352.0000 - rmse: 11596.3936 - val_loss: 141427040.0000 - val_rmse: 11892.3105\n",
      "Epoch 66/120\n",
      "50/50 [==============================] - 49s 986ms/step - loss: 112304176.0000 - rmse: 10597.3662 - val_loss: 142314656.0000 - val_rmse: 11929.5703\n",
      "Epoch 67/120\n",
      "50/50 [==============================] - 48s 960ms/step - loss: 123971960.0000 - rmse: 11134.2695 - val_loss: 144910192.0000 - val_rmse: 12037.8652\n",
      "Epoch 68/120\n",
      "50/50 [==============================] - 48s 980ms/step - loss: 134403696.0000 - rmse: 11593.2607 - val_loss: 149133056.0000 - val_rmse: 12212.0049\n",
      "Epoch 69/120\n",
      "50/50 [==============================] - 48s 965ms/step - loss: 107354248.0000 - rmse: 10361.1895 - val_loss: 147819008.0000 - val_rmse: 12158.0840\n",
      "Epoch 70/120\n",
      "50/50 [==============================] - 48s 973ms/step - loss: 133282680.0000 - rmse: 11544.8115 - val_loss: 145340432.0000 - val_rmse: 12055.7217\n",
      "Epoch 71/120\n",
      "50/50 [==============================] - 48s 969ms/step - loss: 125688512.0000 - rmse: 11211.0889 - val_loss: 152393728.0000 - val_rmse: 12344.7852\n",
      "Epoch 72/120\n",
      "50/50 [==============================] - 49s 983ms/step - loss: 118833968.0000 - rmse: 10901.0996 - val_loss: 147134672.0000 - val_rmse: 12129.9082\n",
      "Epoch 73/120\n",
      "50/50 [==============================] - 48s 966ms/step - loss: 145952080.0000 - rmse: 12081.0625 - val_loss: 149899392.0000 - val_rmse: 12243.3408\n",
      "Epoch 74/120\n",
      "50/50 [==============================] - 49s 989ms/step - loss: 136342848.0000 - rmse: 11676.5938 - val_loss: 152144080.0000 - val_rmse: 12334.6699\n",
      "Epoch 75/120\n",
      "50/50 [==============================] - 48s 967ms/step - loss: 110860080.0000 - rmse: 10529.0117 - val_loss: 146413424.0000 - val_rmse: 12100.1416\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00075: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=(HEIGHT, WIDTH, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(loss = 'mean_squared_error', \n",
    "              optimizer=keras.optimizers.Adam(1e-5), \n",
    "              metrics=[RootMeanSquaredError(name=\"rmse\")])\n",
    "\n",
    "STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=10, verbose=1, mode='auto',\n",
    "        restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_generator, epochs=120, steps_per_epoch=50, \n",
    "                    validation_data = val_generator, callbacks=[monitor],\n",
    "                    verbose = 1, validation_steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f8f385",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T23:11:36.625920Z",
     "iopub.status.busy": "2022-04-16T23:11:36.625066Z",
     "iopub.status.idle": "2022-04-16T23:12:53.240316Z",
     "shell.execute_reply": "2022-04-16T23:12:53.239793Z"
    },
    "papermill": {
     "duration": 77.876069,
     "end_time": "2022-04-16T23:12:53.240479",
     "exception": false,
     "start_time": "2022-04-16T23:11:35.364410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "pred = model.predict(test_generator,steps=len(df_test))\n",
    "\n",
    "df_submit = pd.DataFrame({'id':df_test['id'],'distance':pred.flatten()})\n",
    "df_submit.to_csv(\"submit.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac5af3",
   "metadata": {
    "papermill": {
     "duration": 1.223163,
     "end_time": "2022-04-16T23:12:55.671557",
     "exception": false,
     "start_time": "2022-04-16T23:12:54.448394",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4926.520242,
   "end_time": "2022-04-16T23:12:59.742276",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-16T21:50:53.222034",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
