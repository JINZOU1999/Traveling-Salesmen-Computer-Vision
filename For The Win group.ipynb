{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f18729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:05:57.359584Z",
     "iopub.status.busy": "2022-04-18T20:05:57.357908Z",
     "iopub.status.idle": "2022-04-18T20:06:02.799804Z",
     "shell.execute_reply": "2022-04-18T20:06:02.798831Z",
     "shell.execute_reply.started": "2022-04-18T19:48:40.439113Z"
    },
    "papermill": {
     "duration": 5.456971,
     "end_time": "2022-04-18T20:06:02.799967",
     "exception": false,
     "start_time": "2022-04-18T20:05:57.342996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "PATH = \"/kaggle/input/tsp-cv\"\n",
    "PATH_TRAIN = os.path.join(PATH, \"train.csv\")\n",
    "PATH_TEST = os.path.join(PATH , 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65297fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:06:02.826914Z",
     "iopub.status.busy": "2022-04-18T20:06:02.825941Z",
     "iopub.status.idle": "2022-04-18T20:06:02.881643Z",
     "shell.execute_reply": "2022-04-18T20:06:02.882038Z",
     "shell.execute_reply.started": "2022-03-30T19:17:19.421633Z"
    },
    "papermill": {
     "duration": 0.070029,
     "end_time": "2022-04-18T20:06:02.882162",
     "exception": false,
     "start_time": "2022-04-18T20:06:02.812133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.jpg</td>\n",
       "      <td>83110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>20756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>13286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>13924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16013</th>\n",
       "      <td>16014</td>\n",
       "      <td>16014.jpg</td>\n",
       "      <td>1803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16014</th>\n",
       "      <td>16015</td>\n",
       "      <td>16015.jpg</td>\n",
       "      <td>12492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16015</th>\n",
       "      <td>16016</td>\n",
       "      <td>16016.jpg</td>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16016</th>\n",
       "      <td>16017</td>\n",
       "      <td>16017.jpg</td>\n",
       "      <td>16507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16017</th>\n",
       "      <td>16018</td>\n",
       "      <td>16018.jpg</td>\n",
       "      <td>2363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16018 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   filename  distance\n",
       "0          0      0.jpg     83110\n",
       "1          1      1.jpg      1035\n",
       "2          2      2.jpg     20756\n",
       "3          3      3.jpg     13286\n",
       "4          4      4.jpg     13924\n",
       "...      ...        ...       ...\n",
       "16013  16014  16014.jpg      1803\n",
       "16014  16015  16015.jpg     12492\n",
       "16015  16016  16016.jpg      1556\n",
       "16016  16017  16017.jpg     16507\n",
       "16017  16018  16018.jpg      2363\n",
       "\n",
       "[16018 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16019</td>\n",
       "      <td>16019.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16020</td>\n",
       "      <td>16020.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16021</td>\n",
       "      <td>16021.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16022</td>\n",
       "      <td>16022.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16023</td>\n",
       "      <td>16023.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>20019</td>\n",
       "      <td>20019.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>20020</td>\n",
       "      <td>20020.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>20021</td>\n",
       "      <td>20021.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>20022</td>\n",
       "      <td>20022.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>20023</td>\n",
       "      <td>20023.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4005 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   filename\n",
       "0     16019  16019.jpg\n",
       "1     16020  16020.jpg\n",
       "2     16021  16021.jpg\n",
       "3     16022  16022.jpg\n",
       "4     16023  16023.jpg\n",
       "...     ...        ...\n",
       "4000  20019  20019.jpg\n",
       "4001  20020  20020.jpg\n",
       "4002  20021  20021.jpg\n",
       "4003  20022  20022.jpg\n",
       "4004  20023  20023.jpg\n",
       "\n",
       "[4005 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv(PATH_TRAIN)\n",
    "df_test = pd.read_csv(PATH_TEST)\n",
    "display(df_train)\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d573dd9c",
   "metadata": {
    "papermill": {
     "duration": 0.01156,
     "end_time": "2022-04-18T20:06:02.905570",
     "exception": false,
     "start_time": "2022-04-18T20:06:02.894010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We want to use early stopping.  To do this, we need a validation set.  We will break the data into 80 percent test data and 20 validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5205a8b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:06:02.939197Z",
     "iopub.status.busy": "2022-04-18T20:06:02.938428Z",
     "iopub.status.idle": "2022-04-18T20:06:02.950488Z",
     "shell.execute_reply": "2022-04-18T20:06:02.950064Z",
     "shell.execute_reply.started": "2022-03-30T19:17:37.389607Z"
    },
    "papermill": {
     "duration": 0.033539,
     "end_time": "2022-04-18T20:06:02.950597",
     "exception": false,
     "start_time": "2022-04-18T20:06:02.917058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 14416\n",
      "Validate size: 1602\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.jpg</td>\n",
       "      <td>83110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>20756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>13286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>13924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14411</th>\n",
       "      <td>14412</td>\n",
       "      <td>14412.jpg</td>\n",
       "      <td>10152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14412</th>\n",
       "      <td>14413</td>\n",
       "      <td>14413.jpg</td>\n",
       "      <td>4605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14413</th>\n",
       "      <td>14414</td>\n",
       "      <td>14414.jpg</td>\n",
       "      <td>42715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14414</th>\n",
       "      <td>14415</td>\n",
       "      <td>14415.jpg</td>\n",
       "      <td>17875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14415</th>\n",
       "      <td>14416</td>\n",
       "      <td>14416.jpg</td>\n",
       "      <td>2937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14416 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   filename  distance\n",
       "0          0      0.jpg     83110\n",
       "1          1      1.jpg      1035\n",
       "2          2      2.jpg     20756\n",
       "3          3      3.jpg     13286\n",
       "4          4      4.jpg     13924\n",
       "...      ...        ...       ...\n",
       "14411  14412  14412.jpg     10152\n",
       "14412  14413  14413.jpg      4605\n",
       "14413  14414  14414.jpg     42715\n",
       "14414  14415  14415.jpg     17875\n",
       "14415  14416  14416.jpg      2937\n",
       "\n",
       "[14416 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14416</th>\n",
       "      <td>14417</td>\n",
       "      <td>14417.jpg</td>\n",
       "      <td>18399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14417</th>\n",
       "      <td>14418</td>\n",
       "      <td>14418.jpg</td>\n",
       "      <td>14557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14418</th>\n",
       "      <td>14419</td>\n",
       "      <td>14419.jpg</td>\n",
       "      <td>33278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14419</th>\n",
       "      <td>14420</td>\n",
       "      <td>14420.jpg</td>\n",
       "      <td>9838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14420</th>\n",
       "      <td>14421</td>\n",
       "      <td>14421.jpg</td>\n",
       "      <td>5092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16013</th>\n",
       "      <td>16014</td>\n",
       "      <td>16014.jpg</td>\n",
       "      <td>1803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16014</th>\n",
       "      <td>16015</td>\n",
       "      <td>16015.jpg</td>\n",
       "      <td>12492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16015</th>\n",
       "      <td>16016</td>\n",
       "      <td>16016.jpg</td>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16016</th>\n",
       "      <td>16017</td>\n",
       "      <td>16017.jpg</td>\n",
       "      <td>16507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16017</th>\n",
       "      <td>16018</td>\n",
       "      <td>16018.jpg</td>\n",
       "      <td>2363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1602 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   filename  distance\n",
       "14416  14417  14417.jpg     18399\n",
       "14417  14418  14418.jpg     14557\n",
       "14418  14419  14419.jpg     33278\n",
       "14419  14420  14420.jpg      9838\n",
       "14420  14421  14421.jpg      5092\n",
       "...      ...        ...       ...\n",
       "16013  16014  16014.jpg      1803\n",
       "16014  16015  16015.jpg     12492\n",
       "16015  16016  16016.jpg      1556\n",
       "16016  16017  16017.jpg     16507\n",
       "16017  16018  16018.jpg      2363\n",
       "\n",
       "[1602 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_PCT = 0.9\n",
    "TRAIN_CUT = int(len(df_train) * TRAIN_PCT)\n",
    "\n",
    "df_train_cut = df_train[0:TRAIN_CUT]\n",
    "df_validate_cut = df_train[TRAIN_CUT:]\n",
    "\n",
    "print(f\"Training size: {len(df_train_cut)}\")\n",
    "print(f\"Validate size: {len(df_validate_cut)}\")\n",
    "display(df_train_cut)\n",
    "display(df_validate_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae39a9ba",
   "metadata": {
    "papermill": {
     "duration": 0.012654,
     "end_time": "2022-04-18T20:06:02.976033",
     "exception": false,
     "start_time": "2022-04-18T20:06:02.963379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we create the generators that will provide the images to the neural network as it is trained.  We normalize the images so that the RGB colors between 0-255 become ratios between 0 and 1.  We also use the **flow_from_dataframe** generator to connect the Pandas dataframe to the actual image files. We see here a straightforward implementation; you might also wish to use some of the image transformations provided by the data generator.\n",
    "\n",
    "The **HEIGHT** and **WIDTH** constants specify the dimensions that the image will be scaled (or expanded) to. It is probably not a good idea to expand the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caec7e19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:06:03.010296Z",
     "iopub.status.busy": "2022-04-18T20:06:03.009204Z",
     "iopub.status.idle": "2022-04-18T20:06:10.596742Z",
     "shell.execute_reply": "2022-04-18T20:06:10.597121Z",
     "shell.execute_reply.started": "2022-03-30T19:29:39.672758Z"
    },
    "papermill": {
     "duration": 7.608498,
     "end_time": "2022-04-18T20:06:10.597293",
     "exception": false,
     "start_time": "2022-04-18T20:06:02.988795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14416 validated image filenames.\n",
      "Found 1602 validated image filenames.\n",
      "Found 4005 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# WIDTH = 299\n",
    "# HEIGHT = 299\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "  rescale = 1./255,\n",
    "  horizontal_flip=True,\n",
    "  #vertical_flip=True,\n",
    "  fill_mode='nearest')\n",
    "\n",
    "train_generator = training_datagen.flow_from_dataframe(\n",
    "        dataframe=df_train_cut,\n",
    "        directory=PATH,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"distance\",\n",
    "        target_size=(HEIGHT, WIDTH),\n",
    "        batch_size=32, # Keeping the training batch size small USUALLY increases performance\n",
    "        class_mode='raw')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "val_generator = validation_datagen.flow_from_dataframe(\n",
    "        dataframe=df_validate_cut,\n",
    "        directory=PATH,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"distance\",\n",
    "        target_size=(HEIGHT, WIDTH),\n",
    "        batch_size=256, # Make the validation batch size as large as you have memory for\n",
    "        class_mode='raw')\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_generator = validation_datagen.flow_from_dataframe(\n",
    "        dataframe=df_test,\n",
    "        directory=PATH,\n",
    "        x_col=\"filename\",\n",
    "    \n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        target_size=(HEIGHT, WIDTH),\n",
    "        class_mode=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d82c57",
   "metadata": {
    "papermill": {
     "duration": 0.013597,
     "end_time": "2022-04-18T20:06:10.624938",
     "exception": false,
     "start_time": "2022-04-18T20:06:10.611341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transfer Learning\n",
    "\n",
    "We will now use a ResNet neural network as a basis for our neural network.  We will redefine both the input shape and output of the ResNet model, so we will not transfer the weights.  Since we redefine the input; the weights are of minimal value.  We begin by loading, from Keras, the ResNet50 network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8a8fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:06:10.657912Z",
     "iopub.status.busy": "2022-04-18T20:06:10.657113Z",
     "iopub.status.idle": "2022-04-18T20:06:15.818842Z",
     "shell.execute_reply": "2022-04-18T20:06:15.818368Z",
     "shell.execute_reply.started": "2022-03-30T01:41:06.017711Z"
    },
    "papermill": {
     "duration": 5.180272,
     "end_time": "2022-04-18T20:06:15.818971",
     "exception": false,
     "start_time": "2022-04-18T20:06:10.638699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 20:06:10.754540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:06:10.853531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:06:10.854342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:06:10.855950: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-18 20:06:10.857110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:06:10.857824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:06:10.858461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:06:12.503522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:06:12.504395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:06:12.505070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-18 20:06:12.505677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29089792/29084464 [==============================] - 0s 0us/step\n",
      "29097984/29084464 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import Xception,DenseNet121\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Input\n",
    "#https://www.kaggle.com/code/abnera/transfer-learning-keras-xception-cnn/script\n",
    "input_tensor = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "\n",
    "base_model = DenseNet121(\n",
    "    include_top=False, weights='imagenet', input_tensor=input_tensor,\n",
    "    input_shape=None)\n",
    "\n",
    "#base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca3d083",
   "metadata": {
    "papermill": {
     "duration": 0.016904,
     "end_time": "2022-04-18T20:06:15.853086",
     "exception": false,
     "start_time": "2022-04-18T20:06:15.836182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we must add a few layers to the end of the neural network so that it becomes a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbc40902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:06:15.892575Z",
     "iopub.status.busy": "2022-04-18T20:06:15.891949Z",
     "iopub.status.idle": "2022-04-18T20:06:15.937496Z",
     "shell.execute_reply": "2022-04-18T20:06:15.937045Z"
    },
    "papermill": {
     "duration": 0.068084,
     "end_time": "2022-04-18T20:06:15.937604",
     "exception": false,
     "start_time": "2022-04-18T20:06:15.869520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "#https://vigneshgig.medium.com/xception-neural-network-transfer-learning-and-data-processing-using-ai-c3e7a4ea7bf2\n",
    "#https://www.kaggle.com/code/abnera/transfer-learning-keras-xception-cnn/script\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(2048,activation='relu')(x) \n",
    "x=Dense(2048,activation='relu')(x) \n",
    "model=Model(inputs=base_model.input,outputs=Dense(1)(x))\n",
    "# predictions = Dense(2, activation='softmax')(x)\n",
    "# model = Model(base_model.input, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad86494",
   "metadata": {
    "papermill": {
     "duration": 0.01812,
     "end_time": "2022-04-18T20:06:15.972432",
     "exception": false,
     "start_time": "2022-04-18T20:06:15.954312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we train just like before, the only difference is that we do not define the entire neural network here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e67d3fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:06:16.012065Z",
     "iopub.status.busy": "2022-04-18T20:06:16.011101Z",
     "iopub.status.idle": "2022-04-18T22:07:44.290872Z",
     "shell.execute_reply": "2022-04-18T22:07:44.288883Z"
    },
    "papermill": {
     "duration": 7288.301968,
     "end_time": "2022-04-18T22:07:44.291046",
     "exception": false,
     "start_time": "2022-04-18T20:06:15.989078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 20:06:16.801993: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-18 20:06:27.470315: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 232s 478ms/step - loss: 117795008.0000 - rmse: 10853.3408 - val_loss: 239837696.0000 - val_rmse: 15486.6943\n",
      "Epoch 2/200\n",
      "450/450 [==============================] - 150s 333ms/step - loss: 33010874.0000 - rmse: 5745.5088 - val_loss: 184829632.0000 - val_rmse: 13595.2061\n",
      "Epoch 3/200\n",
      "450/450 [==============================] - 152s 337ms/step - loss: 24102728.0000 - rmse: 4909.4531 - val_loss: 89866088.0000 - val_rmse: 9479.7725\n",
      "Epoch 4/200\n",
      "450/450 [==============================] - 150s 334ms/step - loss: 15463271.0000 - rmse: 3932.3367 - val_loss: 14996076.0000 - val_rmse: 3872.4768\n",
      "Epoch 5/200\n",
      "450/450 [==============================] - 151s 335ms/step - loss: 14413373.0000 - rmse: 3796.4949 - val_loss: 185412560.0000 - val_rmse: 13616.6279\n",
      "Epoch 6/200\n",
      "450/450 [==============================] - 153s 340ms/step - loss: 19247150.0000 - rmse: 4387.1572 - val_loss: 460933504.0000 - val_rmse: 21469.3613\n",
      "Epoch 7/200\n",
      "450/450 [==============================] - 153s 340ms/step - loss: 15097595.0000 - rmse: 3885.5625 - val_loss: 615914432.0000 - val_rmse: 24817.6230\n",
      "Epoch 8/200\n",
      "450/450 [==============================] - 154s 342ms/step - loss: 13317808.0000 - rmse: 3649.3572 - val_loss: 8216869.5000 - val_rmse: 2866.5083\n",
      "Epoch 9/200\n",
      "450/450 [==============================] - 154s 342ms/step - loss: 11331756.0000 - rmse: 3366.2673 - val_loss: 12990339.0000 - val_rmse: 3604.2112\n",
      "Epoch 10/200\n",
      "450/450 [==============================] - 154s 342ms/step - loss: 11284914.0000 - rmse: 3359.3025 - val_loss: 8780000.0000 - val_rmse: 2963.1064\n",
      "Epoch 11/200\n",
      "450/450 [==============================] - 155s 344ms/step - loss: 13000950.0000 - rmse: 3605.6831 - val_loss: 21803202.0000 - val_rmse: 4669.3901\n",
      "Epoch 12/200\n",
      "450/450 [==============================] - 155s 343ms/step - loss: 10114353.0000 - rmse: 3180.3071 - val_loss: 55418716.0000 - val_rmse: 7444.3750\n",
      "Epoch 13/200\n",
      "450/450 [==============================] - 156s 346ms/step - loss: 14193654.0000 - rmse: 3767.4465 - val_loss: 13763837.0000 - val_rmse: 3709.9646\n",
      "Epoch 14/200\n",
      "450/450 [==============================] - 155s 345ms/step - loss: 9272433.0000 - rmse: 3045.0669 - val_loss: 4265357.5000 - val_rmse: 2065.2742\n",
      "Epoch 15/200\n",
      "450/450 [==============================] - 156s 346ms/step - loss: 11274471.0000 - rmse: 3357.7478 - val_loss: 8394153.0000 - val_rmse: 2897.2664\n",
      "Epoch 16/200\n",
      "450/450 [==============================] - 157s 348ms/step - loss: 9091828.0000 - rmse: 3015.2659 - val_loss: 13726637.0000 - val_rmse: 3704.9478\n",
      "Epoch 17/200\n",
      "450/450 [==============================] - 157s 349ms/step - loss: 7944742.5000 - rmse: 2818.6418 - val_loss: 11006675.0000 - val_rmse: 3317.6309\n",
      "Epoch 18/200\n",
      "450/450 [==============================] - 157s 349ms/step - loss: 8643402.0000 - rmse: 2939.9663 - val_loss: 7755576.0000 - val_rmse: 2784.8835\n",
      "Epoch 19/200\n",
      "450/450 [==============================] - 159s 353ms/step - loss: 7729822.5000 - rmse: 2780.2559 - val_loss: 102555176.0000 - val_rmse: 10126.9531\n",
      "Epoch 20/200\n",
      "450/450 [==============================] - 159s 353ms/step - loss: 7171853.0000 - rmse: 2678.0315 - val_loss: 5276885.5000 - val_rmse: 2297.1472\n",
      "Epoch 21/200\n",
      "450/450 [==============================] - 157s 349ms/step - loss: 7100690.5000 - rmse: 2664.7122 - val_loss: 26437704.0000 - val_rmse: 5141.7607\n",
      "Epoch 22/200\n",
      "450/450 [==============================] - 158s 350ms/step - loss: 6547695.0000 - rmse: 2558.8464 - val_loss: 4823997.5000 - val_rmse: 2196.3601\n",
      "Epoch 23/200\n",
      "450/450 [==============================] - 159s 353ms/step - loss: 9442780.0000 - rmse: 3072.9106 - val_loss: 89125360.0000 - val_rmse: 9440.6230\n",
      "Epoch 24/200\n",
      "450/450 [==============================] - 158s 351ms/step - loss: 7628239.5000 - rmse: 2761.9268 - val_loss: 48733276.0000 - val_rmse: 6980.9224\n",
      "Epoch 25/200\n",
      "450/450 [==============================] - 160s 355ms/step - loss: 6997274.0000 - rmse: 2645.2361 - val_loss: 11778068.0000 - val_rmse: 3431.9189\n",
      "Epoch 26/200\n",
      "450/450 [==============================] - 160s 355ms/step - loss: 7519618.0000 - rmse: 2742.1921 - val_loss: 62267708.0000 - val_rmse: 7890.9893\n",
      "Epoch 27/200\n",
      "450/450 [==============================] - 159s 352ms/step - loss: 6800711.0000 - rmse: 2607.8174 - val_loss: 289025504.0000 - val_rmse: 17000.7500\n",
      "Epoch 28/200\n",
      "450/450 [==============================] - 157s 349ms/step - loss: 7931628.0000 - rmse: 2816.3147 - val_loss: 4515946.0000 - val_rmse: 2125.0754\n",
      "Epoch 29/200\n",
      "450/450 [==============================] - 158s 351ms/step - loss: 6080766.5000 - rmse: 2465.9211 - val_loss: 91298984.0000 - val_rmse: 9555.0498\n",
      "Epoch 30/200\n",
      "450/450 [==============================] - 159s 353ms/step - loss: 5992551.5000 - rmse: 2447.9688 - val_loss: 141056080.0000 - val_rmse: 11876.7031\n",
      "Epoch 31/200\n",
      "450/450 [==============================] - 156s 346ms/step - loss: 5893556.5000 - rmse: 2427.6648 - val_loss: 4744573.0000 - val_rmse: 2178.2041\n",
      "Epoch 32/200\n",
      "450/450 [==============================] - 159s 353ms/step - loss: 5018796.0000 - rmse: 2240.2668 - val_loss: 6684202.5000 - val_rmse: 2585.3826\n",
      "Epoch 33/200\n",
      "450/450 [==============================] - 157s 349ms/step - loss: 6710184.5000 - rmse: 2590.4023 - val_loss: 20769168.0000 - val_rmse: 4557.3203\n",
      "Epoch 34/200\n",
      "450/450 [==============================] - 157s 348ms/step - loss: 5217240.5000 - rmse: 2284.1279 - val_loss: 4375501.0000 - val_rmse: 2091.7698\n",
      "Epoch 35/200\n",
      "450/450 [==============================] - 159s 354ms/step - loss: 5764038.0000 - rmse: 2400.8411 - val_loss: 7630448.5000 - val_rmse: 2762.3267\n",
      "Epoch 36/200\n",
      "450/450 [==============================] - 155s 345ms/step - loss: 4603674.0000 - rmse: 2145.6174 - val_loss: 46051488.0000 - val_rmse: 6786.1245\n",
      "Epoch 37/200\n",
      "450/450 [==============================] - 158s 350ms/step - loss: 3967866.2500 - rmse: 1991.9503 - val_loss: 144894848.0000 - val_rmse: 12037.2275\n",
      "Epoch 38/200\n",
      "450/450 [==============================] - 161s 357ms/step - loss: 4284708.5000 - rmse: 2069.9539 - val_loss: 44658360.0000 - val_rmse: 6682.6909\n",
      "Epoch 39/200\n",
      "450/450 [==============================] - 157s 349ms/step - loss: 5963113.5000 - rmse: 2441.9487 - val_loss: 27521174.0000 - val_rmse: 5246.0625\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow import keras\n",
    "# Important, calculate a valid step size for the validation dataset\n",
    "STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "base_model.trainable = True\n",
    "model.compile(loss = 'mean_squared_error', optimizer=keras.optimizers.Adam(1e-3), metrics=[RootMeanSquaredError(name=\"rmse\")])\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=25, verbose=1, mode='auto',\n",
    "        restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_generator, epochs=200, steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                    validation_data = val_generator, callbacks=[monitor],\n",
    "                    verbose = 1, validation_steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c54e7874",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T22:07:55.769986Z",
     "iopub.status.busy": "2022-04-18T22:07:55.769122Z",
     "iopub.status.idle": "2022-04-18T22:10:19.217212Z",
     "shell.execute_reply": "2022-04-18T22:10:19.216730Z"
    },
    "papermill": {
     "duration": 149.134323,
     "end_time": "2022-04-18T22:10:19.217390",
     "exception": false,
     "start_time": "2022-04-18T22:07:50.083067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "pred = model.predict(test_generator,steps=len(df_test))\n",
    "\n",
    "df_submit = pd.DataFrame({'id':df_test['id'],'distance':pred.flatten()})\n",
    "df_submit.to_csv(\"submit.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40415028",
   "metadata": {
    "papermill": {
     "duration": 5.725758,
     "end_time": "2022-04-18T22:10:30.476623",
     "exception": false,
     "start_time": "2022-04-18T22:10:24.750865",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7490.147299,
   "end_time": "2022-04-18T22:10:39.076040",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-18T20:05:48.928741",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
